{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ú®This Jupyter notebook allows you to run Python code interactively üêç‚ú®\n",
    "\n",
    "## Getting Started\n",
    "1. Click the `Select Kernel` button at the top right.\n",
    "2. Choose Python environments and select `Python 3.11.9`.\n",
    "\n",
    "Run each section of the notebook by clicking the play button on the left side of the code cells.\n",
    "\n",
    "## Learning Outcomes\n",
    "We will focus on four key outcomes:\n",
    "\n",
    "1. Understanding agents and prompt engineering with Prompty.\n",
    "2. Utilizing Prompty tracing for debugging and observability.\n",
    "3. Building and running Contoso Creative Writer.\n",
    "4. Setting up automated evaluations with GitHub Actions.\n",
    "\n",
    "Let‚Äôs start with the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Agents and Prompt Engineering with Prompty\n",
    "### i. What are AI agents?\n",
    "Contoso Creative Writer is an Agentic Application. In AI, an agent is a program designed to:\n",
    "\n",
    "- Perceive its environment\n",
    "- Make decisions\n",
    "- Take actions to achieve specific goals\n",
    "\n",
    "For Contoso Creative Writer, the goal is to help the marketing team at Contoso Outdoors write well-researched, product-specific articles. \n",
    "\n",
    "Contoso Creative Writer is made up of 4 agents that help achieve this goal: \n",
    "\n",
    "<img src=\"agents.png\" alt=\"Agents in Contoso Creative Writer\" width=\"900\" height=\"380\">\n",
    "\n",
    "In the file explorer to the left open the `src/api/agents` folder. This folder contains 4 sub-folders, one for each agent!\n",
    "\n",
    "### ii. Understanding how to build an agent with Prompty and Azure OpenAI\n",
    "\n",
    "\n",
    "#### Each agent is built with generally the same 3 files: \n",
    "\n",
    "1. `functions.json`: Describes any tools/functions available to the agent. (Some agents don't need tools besides the LLM and will not need this file.)\n",
    "\n",
    "2. `agentname.py`: A file where the tools are created with code and a function is written to pass user input, a prompty file and any other information to the LLM. \n",
    "\n",
    "3. `agentname.prompty`: A file where the agents base prompt is written and LLM configurations are defined. \n",
    "\n",
    "#### Using the researcher agent to understand how an agent is structured:\n",
    "\n",
    "To help us understand how an agent is built we will focus on the Researcher Agent.\n",
    "To see it in action, click the play button to the left of the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../src/api/agents/researcher'))\n",
    "\n",
    "from researcher import research\n",
    "\n",
    "instructions = \"Can you find the best educational material for learning Python programming.\"\n",
    "\n",
    "research(instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the instructions to research a topic you‚Äôre interested in, for example, ‚ÄúCan you find the best educational material for learning about AI Agents?‚Äù\n",
    "\n",
    "#### How does the Researcher agent work? \n",
    "\n",
    "As expected the researcher folder contains 3 files. Open the reseacrher folder in the file explorer and click on each file to examine it. \n",
    "\n",
    "<img src=\"researcher_agent_files.png\" alt=\"Files in researcher agent\" width=\"900\" height=\"380\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how the researcher agent works, let's see how we can edit the user instructions or prompt to influence what the agent does. \n",
    "\n",
    "### iii. Prompt engineering with user instructions \n",
    "\n",
    "Prompt engineering is the process of designing and refining input prompts to guide generative AI models. With Prompty we can easily test and iterate by changing the user instructions or the base prompt to get better results from the LLM. \n",
    "\n",
    "To illustrate this let's change the instructions we send to the LLM to guide it to use a specific function. \n",
    "\n",
    "In our earlier example you likely had your results returned from the **find_information** function which returns its results in the `web` category, but you'll notice the `entities` and `news` categories are empty since their associated functions weren't called. The instructions we use can change this! \n",
    "\n",
    "#### Find entities: \n",
    "\n",
    "this function is used to find information about people or places. Let's ask the LLM to find information about Guido van Rossum the creator of Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Can you tell me about the person Guido van Rossum?\"\n",
    "\n",
    "research(instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find news: \n",
    "\n",
    "This function is used to find news. Let's ask the LLM to find the latest news about Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Can you find the latest news about Microsoft? \"\n",
    "\n",
    "research(instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### iv. Build a custom social media agent and changing the base prompt\n",
    "\n",
    "Now that we know how an agent is generally created, let's build a custom one for ourselves! \n",
    "\n",
    "You should see a `socialmedia` folder in the file explorer to the left. This folder contains:\n",
    "\n",
    "- The `functions.json` and `researcher.prompty` files for running the researcher agent:  We'll use these to keep getting information from the web. \n",
    "\n",
    "- A new `social.py` file: This is similar to researcher.py file but adds in the `execute_social_prompty` and `run_social_media_agent` functions. \n",
    "\n",
    "- A new `social.prompty` file: This contains the prompt for the social media agent.\n",
    "\n",
    "To run this agent we will need to provide research instructions for which topics to search for online and instructions on what sort of social media content you want. \n",
    "Run the cell below to test it out! \n",
    "\n",
    "Currently the agent is set to generate twitter content and does not include links in the returned output. \n",
    "\n",
    "Edit the `social.prompty` file to generate content for another social media site like LinkedIn and to have it include url links in the response. \n",
    "(Look through the researcher.prompty file for inspiration if needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/socialmedia'))\n",
    "\n",
    "from social import run_social_media_agent\n",
    "\n",
    "research_instructions = \"Find information about AI Agents\"\n",
    "social_media_instructions = \"Write a fun and engaging twitter thread about AI Agents given the research.\"\n",
    "\n",
    "run_social_media_agent(instructions=research_instructions, social_media_instructions = social_media_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utilizing Prompty tracing for debugging and observabilty\n",
    "\n",
    "When running Applications driven by LLMs, sometimes things don't go as expected! It's important to have a way to debug your LLM workflow so you can see where things are working. \n",
    "\n",
    "Tracing helps you visualize the execution of your prompts and clearly see what inputs are being passed to the LLM. \n",
    "\n",
    "We'll use tracing to also get a better understanding of what's happening in our workflow by calling the `test_create_article` function that we import from the `orchestrator.py` file. We'll pass through the usual instructions for research and products the agents should get, and some context for what type of article should be written. `test_create_article` will then run all the logic necessary to generate an article. We also set local_tracing to true so that tracing is done locally. \n",
    "\n",
    "Once you can see the article has been generated, a `.runs` folder should appear in the `workshop` folder. Select this folder and click the `.tracy` file in it. \n",
    "This shows you all the Python functions that were called in order to generate the article. Explore each section and see what helpful information you can find that you might use in debugging! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../src/api'))\n",
    "\n",
    "from orchestrator import test_create_article\n",
    "from tracing import init_tracing\n",
    "\n",
    "tracer = init_tracing(local_tracing=True)\n",
    "\n",
    "research_context = \"Can you find the latest camping trends and what folks are doing in the winter?\"\n",
    "product_context = \"Can you use a selection of tents and sleeping bags as context?\"\n",
    "assignment_context = '''Write a fun and engaging article that includes the research and product information. \n",
    "The article should be between 800 and 1000 words.\n",
    "Make sure to cite sources in the article as you mention the research not at the end.'''\n",
    "\n",
    "test_create_article(research_context=research_context, product_context=product_context, assignment_context=assignment_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracing is useful for deugging and observability both locally and in production. \n",
    "\n",
    "Let's now move on to the next section, building and running the full Contoso Creative Writer Application!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building and running Contoso Creative Writer \n",
    "\n",
    "Now that we understand how the application works it's time to build it. \n",
    "\n",
    "To complete these next two learning outcomes you'll need to use the terminal. \n",
    "\n",
    "If it‚Äôs not already visible, you can open it by clicking on the hamburger menu at the top left of the page, clicking Terminal and then selecting New Terminal.\n",
    "\n",
    "Once your terminal is open, copy and past the following commands in the terminal and press enter after each one to run it. \n",
    "\n",
    "1. Starting the FastAPI server \n",
    "\n",
    "    Navigate to the src/api folder  with the following command \n",
    "\n",
    "    ```shell\n",
    "    cd ./src/api\n",
    "    ```\n",
    "\n",
    "    Run the FastAPI webserver with the following command \n",
    "\n",
    "    ```shell\n",
    "    fastapi dev main.py\n",
    "    ```\n",
    "\n",
    "    Do not click open browser if prompted. \n",
    "\n",
    "    Next you'll need to change the visibility of the API's 8000 and 5173 ports to public in the `PORTS` tab. You can do this by right clicking on the visibility section of the port, selecting port visibility and setting it to public. The ports tab should look like this:\n",
    "\n",
    "    <img src=\"../../images/ports.png\" alt=\"Screenshot showing setting port-visibility\" width=\"800px\" />\n",
    "\n",
    "\n",
    "2. Running the web app \n",
    "\n",
    "    Once you've completed the above steps. You'll need to open a **new terminal** and navigate to the web folder. you can open a new terminal by clicking on the hamburger menu at the top left of the page, clicking Terminal and then selecting New Terminal. \n",
    "\n",
    "    In the terminal run the following commands \n",
    "\n",
    "    ```shell\n",
    "    cd ./src/web\n",
    "    ```\n",
    "    \n",
    "    First install node packages:\n",
    "\n",
    "    ```shell\n",
    "    npm install\n",
    "    ```\n",
    "\n",
    "    Then run the web app with a local dev web server:\n",
    "    \n",
    "    ```shell\n",
    "    npm run dev\n",
    "    ```\n",
    "\n",
    "Once you've run the above command you should see an `http://localhost:5173/` link in the terminal. Click this link or click the `open on browser` button that comes up as a Gitub notification in the bottom right corner of the screen. Select the `continue` button and that's it! \n",
    "\n",
    "You can now test out the app by clicking `Example` to fill out the example information and then clicking `Start Work` to get Contoso Creative Writer to generate an article. \n",
    "\n",
    "You can also see which agent steps are being carried out in what order by click on the small bug button at the bottom right of the Application. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting up automated evaluations and deployment with Github Actions \n",
    "\n",
    "Contoso Creative Writer is set up to run a CI/CD pipeline, which stands for Continuous Integration and Continuous Deployment. This is a series of automated steps that streamline the process of delivering software.\n",
    "\n",
    "In this sample code the CI/CD pipeline includes the following: \n",
    "1. **Build and Deploy:** Automatically building and deploying the latest version of the code to production (This helps us confirm things are working as expected.)\n",
    "2. **Evaulations:** Automatically sending example research, product and assignment instructions to Contoso Creative Writer and running evaulations on the produced article to see how fluent, grounded, relevant and x the final response was given the questions. \n",
    "\n",
    "\n",
    "To set up CI/CD with GitHub actions on your repository, **open a new terminal** and: \n",
    "\n",
    "1. Run the following command:\n",
    "\n",
    "    ```shell\n",
    "    azd pipeline config\n",
    "    ```\n",
    "\n",
    "    - select an environment name like yourname-aitour\n",
    "    - select the recommended subscription by pressing enter\n",
    "    - select `Canada East` as the Azure Location \n",
    "    - When asked to Log in using the Github CLI type in `Y`\n",
    "    - Choose `HTTPS` as the preferred protocol for Git Operations \n",
    "    - Select `Y` to Authenticate with your Github credentials. \n",
    "    - Choose Login with a web browser to authenticate Github CLI and follow the authentication instructions. \n",
    "    - You may be asked if you want to commit and push your local changes. Choose `n`\n",
    "    - You should see two links in your terminal. Select the Link to view your pipeline status. \n",
    "\n",
    "2. You should now be on a page that shows all the workflows. It should look similar to the image below. \n",
    "\n",
    "- Click on the workflow named evaluate (outlined in red in the image).\n",
    "- It may need a few minutes to complete but once complete you should see the evaluated results on the page. \n",
    "\n",
    "You should see a table with some scores for relevance, fluencey, coherence and groundedness. The scores are from 1-5, with 5 being the highest mark. These are used to help us know how well the model is performing. This is helpful as a metric and "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
