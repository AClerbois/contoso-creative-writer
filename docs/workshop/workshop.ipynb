{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ú®This Jupyter notebook allows you to run Python code interactively üêç‚ú®\n",
    "\n",
    "## Getting Started\n",
    "1. Click the `Select Kernel` button at the top right.\n",
    "2. Choose Python environments and select `Python 3.11.9`.\n",
    "\n",
    "Run each section of the notebook by clicking the play button on the left side of the code cells.\n",
    "\n",
    "## Learning Outcomes\n",
    "We will focus on four key outcomes:\n",
    "\n",
    "1. Understanding agents and prompt engineering with Prompty.\n",
    "2. Utilizing Prompty tracing for debugging and observability.\n",
    "3. Building and running Contoso Creative Writer.\n",
    "4. Setting up automated evaluations with GitHub Actions.\n",
    "\n",
    "Let‚Äôs start with the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Agents and Prompt Engineering with Prompty\n",
    "### 1.1. What are AI agents?\n",
    "Contoso Creative Writer is an Agentic Application. \n",
    "\n",
    "**In AI, an agent is a program designed to:**\n",
    "\n",
    "- Perceive its environment\n",
    "- Make decisions\n",
    "- Take actions to achieve specific goals\n",
    "\n",
    "For Contoso Creative Writer, the goal is to help the marketing team at Contoso Outdoors write well-researched, product-specific articles. \n",
    "\n",
    "Contoso Creative Writer is made up of 4 agents that help achieve this goal.\n",
    "<br>In the file explorer to the left open and explore the `src/api/agents` folder. This folder contains 4 sub-folders, one for each agent.  \n",
    "\n",
    "<img src=\"agents.png\" alt=\"Agents in Contoso Creative Writer\" width=\"900\" height=\"380\">\n",
    "\n",
    "### 1.2. Understanding how to build an agent with Prompty and Azure OpenAI\n",
    "\n",
    "**Each agent is built with generally the same 3 files:**\n",
    " \n",
    "1. `functions.json`: Describes any tools/functions available to the agent. (Some agents don't need tools besides the LLM and will not need this file.)\n",
    "\n",
    "2. `agentname.py`: A file where the tools are written with code and user input, a prompty file and any other information are passed to the LLM. \n",
    "\n",
    "3. `agentname.prompty`: A file where the agents base prompt is written and LLM configurations are defined. \n",
    "\n",
    "**The Researcher agent:** \n",
    "\n",
    "To help us understand how an agent is built we will focus on the Researcher Agent.\n",
    "<br>To see it in action, click the play button to the left of the cell below.\n",
    "\n",
    "Try changing the instructions to research a topic you‚Äôre interested in, for example, ‚ÄúCan you find the best educational material for learning about AI Agents?‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../src/api/agents/researcher'))\n",
    "\n",
    "from researcher import research\n",
    "\n",
    "instructions = \"Can you find the best educational material for learning Python programming.\"\n",
    "\n",
    "research(instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected for agents built in this project, the researcher folder contains the 3 files described in the image below. \n",
    "<br>Open `src/api/agents/researcher` folder in the file explorer and click on each file to examine it. \n",
    "\n",
    "<img src=\"researcher_agent_files.png\" alt=\"Files in researcher agent\" width=\"900\" height=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how the researcher agent works, let's see how we can edit the user instructions to influence which tools the researcher agent uses.\n",
    "\n",
    "### 1.3. An introduction to prompt engineering with user instructions \n",
    "\n",
    "Prompt engineering is the process of designing and refining input prompts to guide generative AI models. \n",
    "\n",
    "In our earlier example you likely had your results returned from the **find_information** function which returns its results in the `web` category, \n",
    "<br>but you'll notice the `entities` and `news` categories are empty since their associated functions weren't called. \n",
    "<br>We can edit the instructions to guide the LLM to use a specific function! \n",
    "\n",
    "#### Find entities: \n",
    "This function is used to find information about people or places. Let's ask the LLM to find information about Guido van Rossum the creator of Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Can you tell me information about the person Guido van Rossum?\"\n",
    "\n",
    "research(instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find news: \n",
    "This function is used to find news. Let's ask the LLM to find the latest news about Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Can you find the latest news about Microsoft? \"\n",
    "\n",
    "research(instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with LLM's it's important to see that being explicit in your requests will return better results. \n",
    "<br>In the above examples mentioning the phrase 'person' or 'news' influenced which functions were called. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.4. Building a custom social media agent and editing the base prompt\n",
    "\n",
    "<img src=\"socialmediaagent.png\" alt=\"social media agent\" width=\"600\" height=\"350\">\n",
    "\n",
    "Now that we know how an agent is generally created, let's build a custom one for ourselves! \n",
    "\n",
    "You should see a **socialmedia** folder in the workshop folder. This folder contains:\n",
    "\n",
    "- **A `functions.json` and `researcher.prompty` file:** We'll use these to keep the researcher agent going so we can get information from the web. \n",
    "\n",
    "- A new `social.py` file: This is similar to researcher.py file but adds in the `execute_social_media_writer_prompty` and `run_social_media_agent` functions. \n",
    "- **A new `social.py` file:** This is similar to researcher.py file but adds in an `execute_social_prompty` and `run_social_media_agent` function. \n",
    "\n",
    "- **A new `social.prompty` file:** This contains the base prompt for the social media agent.\n",
    "\n",
    "To run this agent we will need to provide research instructions for which topics to search for online and instructions on what sort of social media content you want. \n",
    "<br>Run the cell below to test it out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/socialmedia'))\n",
    "\n",
    "from social import run_social_media_agent\n",
    "\n",
    "research_instructions = \"Find information about AI Agents\"\n",
    "social_media_instructions = \"Write a fun and engaging twitter thread about AI Agents given the research.\"\n",
    "\n",
    "run_social_media_agent(instructions=research_instructions, social_media_instructions = social_media_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Your task in this section is to edit the `social.prompty` file to:**\n",
    "-  generate content for another social media site like LinkedIn\n",
    "-  include url links in the response. \n",
    "\n",
    "Currently the agent is set to generate twitter content and does not include links in the returned output.\n",
    "<br>Look through the researcher.prompty file if you need inspiration and remember to be as explicit as possible! \n",
    "\n",
    "## 2. Utilizing Prompty tracing for debugging and observabilty\n",
    "\n",
    "When running Applications driven by LLMs, sometimes things don't go as expected! It's important to have a way to debug your LLM workflow so you can see where things are working. \n",
    "\n",
    "Tracing helps you visualize the execution of your prompts and clearly see what inputs are being passed to the LLM. \n",
    "\n",
    "We'll use tracing to also get a better understanding of what's happening in our workflow by calling the `test_create_article` function that we import from the `orchestrator.py` file. We'll pass through the usual instructions for research and products the agents should get, and some context for what type of article should be written. `test_create_article` will then run all the logic necessary to generate an article. We also set local_tracing to true so that tracing is done locally. \n",
    "\n",
    "Once you can see the article has been generated, a `.runs` folder should appear in the `workshop` folder. Select this folder and click the `.tracy` file in it. \n",
    "This shows you all the Python functions that were called in order to generate the article. Explore each section and see what helpful information you can find that you might use in debugging! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../src/api'))\n",
    "\n",
    "from orchestrator import test_create_article\n",
    "from tracing import init_tracing\n",
    "\n",
    "tracer = init_tracing(local_tracing=True)\n",
    "\n",
    "research_context = \"Can you find the latest camping trends and what folks are doing in the winter?\"\n",
    "product_context = \"Can you use a selection of tents and sleeping bags as context?\"\n",
    "assignment_context = '''Write a fun and engaging article that includes the research and product information. \n",
    "The article should be between 800 and 1000 words.\n",
    "Make sure to cite sources in the article as you mention the research not at the end.'''\n",
    "\n",
    "test_create_article(research_context=research_context, product_context=product_context, assignment_context=assignment_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracing is useful for deugging and observability both locally and in production. \n",
    "\n",
    "Let's now move on to the next section, building and running the full Contoso Creative Writer Application!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building and running Contoso Creative Writer \n",
    "\n",
    "Now that we understand how the application works it's time to build it. \n",
    "\n",
    "To complete these next two learning outcomes you'll need to use the terminal. \n",
    "\n",
    "If it‚Äôs not already visible, you can open it by clicking on the hamburger menu at the top left of the page, clicking Terminal and then selecting New Terminal.\n",
    "\n",
    "Once your terminal is open, copy and past the following commands in the terminal and press enter after each one to run it. \n",
    "\n",
    "1. Starting the FastAPI server \n",
    "\n",
    "    Navigate to the src/api folder  with the following command \n",
    "\n",
    "    ```shell\n",
    "    cd ./src/api\n",
    "    ```\n",
    "\n",
    "    Run the FastAPI webserver with the following command \n",
    "\n",
    "    ```shell\n",
    "    fastapi dev main.py\n",
    "    ```\n",
    "\n",
    "    Do not click open browser if prompted. \n",
    "\n",
    "    Next you'll need to change the visibility of the API's 8000 and 5173 ports to public in the `PORTS` tab. You can do this by right clicking on the visibility section of the port, selecting port visibility and setting it to public. The ports tab should look like this:\n",
    "\n",
    "    <img src=\"../../images/ports.png\" alt=\"Screenshot showing setting port-visibility\" width=\"800px\" />\n",
    "\n",
    "\n",
    "2. Running the web app \n",
    "\n",
    "    Once you've completed the above steps. You'll need to open a **new terminal** and navigate to the web folder. you can open a new terminal by clicking on the hamburger menu at the top left of the page, clicking Terminal and then selecting New Terminal. \n",
    "\n",
    "    In the terminal run the following commands \n",
    "\n",
    "    ```shell\n",
    "    cd ./src/web\n",
    "    ```\n",
    "    \n",
    "    First install node packages:\n",
    "\n",
    "    ```shell\n",
    "    npm install\n",
    "    ```\n",
    "\n",
    "    Then run the web app with a local dev web server:\n",
    "    \n",
    "    ```shell\n",
    "    npm run dev\n",
    "    ```\n",
    "\n",
    "    Once you've run the above command you should see an `http://localhost:5173/` link in the terminal. Click this link or click the `open on browser` button that comes up as a Gitub notification in the bottom right corner of the screen. Select the `continue` button and you should now see the app appear on your screen!\n",
    "\n",
    "You can now test out the app by clicking `Example` to fill out the example information and then clicking `Start Work` to get Contoso Creative Writer to generate an article. \n",
    "\n",
    "You can also see which agent steps are being carried out in what order by click on the small bug button at the bottom right of the Application. The application with the generated article should look like this: \n",
    "\n",
    "<img src=\"../../images/agent.png\" alt=\"Files in researcher agent\" width=\"900\" height=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting up automated evaluations and deployment with Github Actions \n",
    "\n",
    "Contoso Creative Writer is set up to run a CI/CD pipeline, which stands for Continuous Integration and Continuous Deployment. This is a series of automated steps that streamline the process of delivering software.\n",
    "\n",
    "In this sample code the CI/CD pipeline includes the following: \n",
    "1. **Build and Deploy:** Automatically building and deploying the latest version of the code to production (This helps us confirm things are working as expected.)\n",
    "2. **Evaulations:** Automatically sending example research, product and assignment instructions to Contoso Creative Writer and running evaulations on the produced article to see how fluent, grounded, relevant and x the final response was given the questions. \n",
    "\n",
    "\n",
    "To set up CI/CD with GitHub actions on your repository, **open a new terminal** and: \n",
    "\n",
    "1. Run the following command:\n",
    "\n",
    "    ```shell\n",
    "    azd pipeline config\n",
    "    ```\n",
    "\n",
    "    - select an environment name like yourname-aitour\n",
    "    - select the recommended subscription by pressing enter\n",
    "    - select `Canada East` as the Azure Location \n",
    "    - When asked to Log in using the Github CLI type in `Y`\n",
    "    - Choose `HTTPS` as the preferred protocol for Git Operations \n",
    "    - Select `Y` to Authenticate with your Github credentials. \n",
    "    - Choose Login with a web browser to authenticate Github CLI and follow the authentication instructions. \n",
    "    - You may be asked if you want to commit and push your local changes. Choose `n`\n",
    "    - You should see two links in your terminal. Select the Link to view your pipeline status. \n",
    "\n",
    "2. You should now be on a page that shows all the workflows. It should look similar to the image below. \n",
    "\n",
    "- Click on the workflow named evaluate (outlined in red in the image).\n",
    "- It may need a few minutes to complete but once complete you should see the evaluated results on the page. \n",
    "\n",
    "You should see a table with some scores for relevance, fluencey, coherence and groundedness. The scores are from 1-5, with 5 being the highest mark. These are used to help us know how well the model is performing. This is helpful as a metric and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
