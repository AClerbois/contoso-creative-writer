{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ú®This is a Jupyter Notebook that allows you to run Python code interactively üêç‚ú®\n",
    "\n",
    "## Getting Started\n",
    "1. Click the **Select Kernel** button on the top right of the notebook.\n",
    "2. Choose **Python environments** and select **Python 3.11**.\n",
    "\n",
    "‚ñ∂Ô∏è Note: To run the code in the cells of this notebook click the play button on the left side of the cells that contain code. \n",
    "\n",
    "## Learning Outcomes\n",
    "We will focus on four key outcomes, each split into their own notebook:\n",
    "\n",
    "1. [Understanding agents and prompt engineering with Prompty.](#1-understanding-agents-and-prompt-engineering-with-prompty)\n",
    "2. [Utilizing Prompty tracing for debugging and observability.](./workshop-2-tracing.ipynb)\n",
    "3. [Building and running Contoso Creative Writer.](./workshop-3-build.ipynb)\n",
    "4. [Setting up automated evaluations with GitHub Actions.](./workshop-4-ci-cd.ipynb)\n",
    "\n",
    "Let‚Äôs get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Agents and Prompt Engineering with Prompty\n",
    "### 1.1. What are AI agents?\n",
    "Contoso Creative Writer is an Agentic Application. \n",
    "\n",
    "**In artificial intelligence an agent is a program designed to:**\n",
    "\n",
    "- Perceive its environment\n",
    "- Make decisions\n",
    "- Take actions to achieve specific goals\n",
    "\n",
    "For Contoso Creative Writer, the goal is to help the marketing team at Contoso Outdoors write well-researched, product-specific articles. \n",
    "\n",
    "Contoso Creative Writer is made up of 4 agents that help achieve this goal. \n",
    "\n",
    "<img src=\"../../images/agents.png\" alt=\"Agents in Contoso Creative Writer\" width=\"900\" height=\"380\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. How is an AI agent built?\n",
    "\n",
    "Each agent in Contoso Creative Writer is built with [Prompty](https://prompty.ai/)! \n",
    "\n",
    "#### 1.2.1 What is Prompty?\n",
    "Prompty is a new asset class and file format for LLM prompts that aims to provide observability, understandability, and portability for developers.\n",
    "\n",
    "**The Prompty file:**\n",
    "- A Prompty file is not tied to any language as it uses the markdown format with YAML\n",
    "- The file contains two main parts:\n",
    "    - **Front Mattter:** \n",
    "        - This is the first part of the prompty file \n",
    "        - It is written in YAML and is contained inside two `---` seperators. \n",
    "        - It includes basic details about the prompt, the model configuration and prompty inputs. \n",
    "\n",
    "\n",
    "            <details>\n",
    "            <summary>üí°Click to see an example</summary>\n",
    "            \n",
    "            ```yaml\n",
    "            ---\n",
    "            name: My Prompty File \n",
    "            description: >-\n",
    "            This is a prompt about Prompty\n",
    "            authors:\n",
    "            - Seth Juarez\n",
    "            model:\n",
    "            api: chat\n",
    "            configuration: \n",
    "                type: azure_openai\n",
    "                azure_deployment: gpt-35-turbo\n",
    "                api_version: 2023-07-01-preview\n",
    "            sample:\n",
    "            instructions: Can you tell me more about Prompty?  \n",
    "            ---\n",
    "            ```\n",
    "            </details><br>\n",
    "\n",
    "    - **Prompt Template:** \n",
    "        - This is the base prompt that is sent to the LLM once the prompty is executed. \n",
    "        - It uses Jinja format to pass values either specified in the front matter or from the application to the LLM.\n",
    "        - Given *'name': Marlene*, the variable *{{name}}* will be replaced by *Marlene* at runtime. \n",
    "\n",
    "\n",
    "            <details>\n",
    "            <summary>üí°Click to see an example</summary>\n",
    "            \n",
    "            ```yaml\n",
    "            \n",
    "            system:\n",
    "            You are a helfpul assistant that uses gpt-35-turbo to answer questions about Prompty. \n",
    "            You provide helpful information and reply in a friendly tone\n",
    "\n",
    "            user:\n",
    "            {{instructions}}\n",
    "            ```\n",
    "            </details><br>\n",
    "\n",
    "**The VS Code extension tool:**\n",
    "- The Prompty extension allows you to run Prompty files directly in VS Code. \n",
    "- It has been pre-installed for this workshop, but you can also find it in the Visual Studio Code Marketplace.\n",
    "\n",
    "We'll look at how to use both of these to build and run an AI Agent next. \n",
    "\n",
    "### 1.3. Building an AI Agent\n",
    "\n",
    "To help us understand practically how we build an AI agent will build the **Researcher Agent** step by step.\n",
    "\n",
    "In order to build the Researcher agent you will complete the following 4 steps:\n",
    "- Step 1: Build a multi-lingual query generator\n",
    "- Step 2: Give the LLM information using a json file\n",
    "- Step 3: Understanding LLM function calling with Prompty\n",
    "- Step 4: Build the tools and execute the research\n",
    "\n",
    "Let's start with step 1. \n",
    "\n",
    "#### **Step 1:** Build a multi-lingual query generator\n",
    "The researcher agent generates queries that can be used to look for information online. \n",
    "<br>It also allows us to find search results in multiple languages. \n",
    "\n",
    "Complete the following tasks...\n",
    "\n",
    "---\n",
    "<img src=\"todo.png\" alt=\"todo icon\" width=\"40\" height=\"40\"> **Tasks for you to do:**\n",
    "\n",
    "> **TODO 1:** Open the [researcher-0.prompty](researcher/researcher-0.prompty) file, read the prompt and **click the play button** on the top right of the file.\n",
    "> <br>‚ùóYou will prompted to sign into an account. Choose your skillable email/username to sign in. \n",
    ">\n",
    "> Note: (If you signed in with the wrong account by mistake sign out of that account in the profile section at the bottom right of the codespace and rerun the Prompty file.)\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Observations üëÄ:**\n",
    ">   - Observe the output in the terminal. \n",
    ">   - Look in the Prompty file and notice at the top of the file, the following instructions in the *sample section*:\n",
    ">\n",
    ">       ***instructions:** Can you generate queries to find the latest camping trends and what folks are doing in the winter? Use 'en-US' as the market code.*\n",
    "\n",
    "<br> \n",
    "\n",
    "> **TODO 2:** Edit the instructions to use a new language. (For example use *es-ES* instead of *en-US*, to get the results back in Spanish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"coding.png\" alt=\"todo icon\" width=\"45\" height=\"45\"> **Run the code:**\n",
    "\n",
    "You can also execute a Prompty file using the Prompty Python package. \n",
    "\n",
    "> **TODO 3:** Click the play button to the left of the cell to run *researcher-0.prompty* file in Python.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To find the latest camping trends and winter activities, you could use the following queries tailored for the en-US market code:\n",
       "\n",
       "1. Latest Camping Trends:\n",
       "   Query: \"latest camping trends\" site:.com\n",
       "   This query will search for the most recent articles, blog posts, and news related to camping trends on websites with a .com domain.\n",
       "\n",
       "2. Winter Camping Trends & Tips:\n",
       "   Query: \"winter camping tips\" OR \"winter camping trends\" site:.com\n",
       "   Use this query to find articles providing tips and trends specifically related to winter camping on websites with a .com domain.\n",
       "\n",
       "3. Popular Winter Activities:\n",
       "   Query: \"popular winter activities\" OR \"winter activities\" site:.com\n",
       "   This query will help you discover the most popular winter activities people are engaging in based on content from websites with a .com domain.\n",
       "\n",
       "4. Winter Recreation Trends:\n",
       "   Query: \"winter recreation trends\" OR \"winter outdoor activities\" site:.com\n",
       "   This query can help you identify the latest trends in outdoor activities and recreation during the winter season from websites with a .com domain.\n",
       "\n",
       "By using these queries, you can gather information on the latest camping trends as well as popular winter activities, providing a comprehensive view of outdoor trends and activities in the United States."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prompty.azure\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "\n",
    "instructions = \"Can you generate queries to find the latest camping trends and what folks are doing in the winter? Use 'en-US' as the market code. \"\n",
    "Markdown(prompty.execute(os.getcwd() + \"/researcher/researcher-0.prompty\", inputs={\"instructions\": instructions}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 Complete ‚úÖ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2:** Give the LLM information using a json file\n",
    "Prompty allows us to pass information to the LLM using a json file.\n",
    "\n",
    "- The *${file:filename.json}* syntax can be added to the frontmatter of the prompty file to do this. \n",
    "- The information from the json folder is referenced in the prompt by adding variables in double curly braces e.g {{variablename}}. \n",
    "\n",
    "Complete the following tasks...\n",
    "\n",
    "---\n",
    "<img src=\"todo.png\" alt=\"todo icon\" width=\"40\" height=\"40\"> **Tasks for you to do:**\n",
    "\n",
    "> **TODO 1:** Open the [researcher-1.prompty](researcher/researcher-1.prompty) file, read the prompt and **click the play button** on the top right of the file.\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Observations üëÄ:**\n",
    ">   - Observe the output in the terminal. What is different from the output we saw in step 1? \n",
    ">   - Look in the [researcher-1.prompty](researcher/researcher-1.prompty) file and notice that instead of passing instructions directly in the **sample section** we pass the json file. \n",
    ">  - Look at the [instructions.json](researcher/instructions.json) file. Can you understand how these variables are passed to the prompt in the prompty file? \n",
    " \n",
    "<br>\n",
    "\n",
    " <br>\n",
    "\n",
    "<img src=\"coding.png\" alt=\"todo icon\" width=\"45\" height=\"45\"> **Run the code:**\n",
    "\n",
    " > **TODO 2:** Edit the [instructions.json](researcher/instructions.json) file to return your name instead of the name 'John Smith' and your country instead of 'United States'. \n",
    "> <br>Click the play button to the left of the cell to run the *researcher-1.prompty* file in Python to test that this worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompty.azure\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(prompty.execute(os.getcwd() + \"/researcher/researcher-1.prompty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Observations üëÄ:**\n",
    ">   - Notice that no instructions are passed since we add instructions to the json file. \n",
    ">   - When passing inputs like the instructions to Prompty with a json file you need to use the **inputs** paramater in the prompty file. \n",
    ">   - Look at [researcher-1.prompty](researcher/researcher-1.prompty) to observe this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 Complete ‚úÖ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3:** Understanding LLM function calling with Prompty\n",
    "In order for the researcher to generate even better queries it needs to know which search functions are avaialble to it. \n",
    "- Using the Prompty **tools** parameter the LLM can choose from the functions described in a json file which one it will use to get a relevant answer.  \n",
    "- We can add information about which functions (somtimes called tools), the LLM can use in a *functions.json* file. \n",
    "\n",
    "Complete the following tasks...\n",
    "\n",
    "---\n",
    "<img src=\"todo.png\" alt=\"todo icon\" width=\"40\" height=\"40\"> **Tasks for you to do:**\n",
    "\n",
    "> **TODO 1:** Open the [researcher-2.prompty](researcher/researcher-2.prompty) file, read the prompt and **click the play button** on the top right of the file.\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Observations üëÄ:**\n",
    ">   - Observe the output in the terminal. What do you see is different from the previous output?\n",
    ">   - Note that *${file:functions.json}* has been added to **tools** under the *parameters* section in the [researcher-2.prompty](researcher/researcher-2.prompty) file.\n",
    ">   - Can you see which function was selected by the LLM? \n",
    " \n",
    "<br>\n",
    "\n",
    "<img src=\"coding.png\" alt=\"todo icon\" width=\"45\" height=\"45\"> **Run the code:**\n",
    "\n",
    "In the *researcher-2.prompty* file we passed the following instruction to the LLM:\n",
    "<br>***instructions:** Can you find the best educational material for learning Python programming?*\n",
    "\n",
    "The Prompty template is configured to load the [functions.json](./researcher/functions.json) with the 3 functions:\n",
    "- find_information\n",
    "- find_entities\n",
    "- find_news\n",
    "\n",
    "In the outputs from running the Prompty file we saw that **find_information** was selected. \n",
    "<br> We know from it's description in [functions.json](./researcher/functions.json) that it finds general information on the web. \n",
    "\n",
    "Let's understand further how the LLM selects a function by looking at some Python code. \n",
    "<br>\n",
    "\n",
    "> **TODO 2:** Import the *execute_researcher_prompty* function from the [researcher3.py](./researcher/researcher3.py) script by running the below code cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/researcher'))\n",
    "\n",
    "from researcher3 import execute_researcher_prompty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use *execute_researcher_prompty* to see how by changing the instructions we can influence which function is selected by the LLM.\n",
    "\n",
    "<br>\n",
    "\n",
    "> **TODO 3:** To see how the LLM can help us find people, places or things run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Who is the person who invented the Python programming language?\"\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "function_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Observations üëÄ:**\n",
    ">   - See that the  **find_entities** function was selected by the LLM based on **the description of the function** in [functions.json](./researcher/functions.json) and the **instructions** we passed to it. \n",
    ">   - The LLM also figured out which parameter values should be passed to the function.\n",
    " \n",
    "<br>\n",
    "\n",
    "> **TODO 4:** To see how the LLM can help us **find news** run the cell below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Find the latest news about Microsoft?\"\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "function_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üêû**BUG ALERT:** A bug has purposefully been left in the [functions.json](./researcher/functions.json) file.\n",
    "\n",
    "> **Observations üëÄ:**\n",
    ">   - Which function call has been selected, if any?\n",
    ">   - Is this the function we want? \n",
    ">   - The *find_news* function has not been selected by the LLM. \n",
    ">   - Look in the [functions.json](./researcher/functions.json) file and see what's wrong. \n",
    " \n",
    "<br>\n",
    "\n",
    "> **TODO 6:** Add the function description for **find_news** to the [functions.json](./researcher/functions.json) file. (üí°Click the play icon for the details.)\n",
    "> <br> Once added rerun the cell above! \n",
    "\n",
    "<details>\n",
    "  <summary>find_news function description</summary>\n",
    "  \n",
    "```json\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"find_news\",\n",
    "      \"description\": \"Finds news on the web given a query. This function uses the Bing Search API to find news on the web given a query. The response includes the most relevant news articles from the web and should be used if you're looking for news.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"An optimal search query to find news on the web using the Bing Search API\"\n",
    "          },\n",
    "          \"market\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The market to search in, e.g. en-US - it should match the language of the query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "</details>\n",
    "\n",
    "**Step 3 Complete ‚úÖ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 4:** Build the functions and execute the research\n",
    "The researcher can now selected which function to use and has generated a query and market code to pass to it. \n",
    "\n",
    "- The Python code for these functions that will pass the queries to the Bing Search API is found in the [researcher3.py](researcher/researcher3.py) file. \n",
    "- Open the the [researcher3.py](researcher/researcher3.py) file to see this code and try and understand what each function does. \n",
    "- The notebook cell below calls the *research* function to run code from **researcher3.py**. to run the completed researcher agent.\n",
    "\n",
    "Complete the following task...\n",
    "\n",
    "---\n",
    "<img src=\"todo.png\" alt=\"todo icon\" width=\"40\" height=\"40\"> **Tasks for you to do:**\n",
    "> **TODO:** Run the code in the cell below and test it out with different instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/researcher'))\n",
    "\n",
    "from researcher3 import execute_function_calls\n",
    "\n",
    "instructions = \"Can you find the best educational material for learning Python programming\"\n",
    "\n",
    "# Execute the researcher prompty to get a list of functions calls\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "\n",
    "# Execute the function calls\n",
    "research = execute_function_calls(function_calls)\n",
    "research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Congratulations you've succesfully built your first AI Agent with Promptyüéâ\n",
    "- [‚úÖ] Step 1: Build a multi-lingual query generator\n",
    "- [‚úÖ] Step 2: Give the LLM information using a json file\n",
    "- [‚úÖ] Step 3: Understanding LLM function calling with Prompty\n",
    "- [‚úÖ] Step 4: Build the tools and execute the research\n",
    "\n",
    "We can now succesfully move on to learning outcome 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **Open [next workshop notebook](./workshop-2-tracing.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
