{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ú®This a Jupyter Notebook that allows you to run Python code interactively üêç‚ú®\n",
    "\n",
    "## Getting Started\n",
    "1. Click the **Select Kernel** button on the top right of the notebook.\n",
    "2. Choose **Python environments** and select **Python 3.11.9**.\n",
    "\n",
    "Run code in the notebook by clicking the play button on the left side of the code cells.\n",
    "\n",
    "## Learning Outcomes\n",
    "We will focus on four key outcomes, each split into their own notebook:\n",
    "\n",
    "1. [Understanding agents and prompt engineering with Prompty.](#1-understanding-agents-and-prompt-engineering-with-prompty)\n",
    "2. [Utilizing Prompty tracing for debugging and observability.](#2-utilizing-prompty-tracing-for-debugging-and-observabilty)\n",
    "3. [Building and running Contoso Creative Writer.](#3-building-and-running-contoso-creative-writer)\n",
    "4. [Setting up automated evaluations with GitHub Actions.](#4-setting-up-automated-evaluations-and-deployment-with-github-actions)\n",
    "\n",
    "Let‚Äôs get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Agents and Prompt Engineering with Prompty\n",
    "### 1.1. What are AI agents?\n",
    "Contoso Creative Writer is an Agentic Application. \n",
    "\n",
    "**In artificial intelligence an agent is a program designed to:**\n",
    "\n",
    "- Perceive its environment\n",
    "- Make decisions\n",
    "- Take actions to achieve specific goals\n",
    "\n",
    "For Contoso Creative Writer, the goal is to help the marketing team at Contoso Outdoors write well-researched, product-specific articles. \n",
    "<br>Contoso Creative Writer is made up of 4 agents that help achieve this goal. \n",
    "\n",
    "<img src=\"../../images/agents.png\" alt=\"Agents in Contoso Creative Writer\" width=\"900\" height=\"380\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. How is an AI agent built?\n",
    "\n",
    "Each agent in Contoso Creative Writer is built with [Prompty](https://prompty.ai/)! \n",
    "\n",
    "#### 1.2.1 What is Prompty?\n",
    "Prompty is a new asset class and file format for LLM prompts that aims to provide observability, understandability, and portability for developers.\n",
    "\n",
    "**The Prompty file:**\n",
    "- A Prompty file is not tied to any language as it uses the markdown format with YAML\n",
    "- The file contains two main parts:\n",
    "    - **Front Mattter:** \n",
    "        - This is the first part of the prompty file \n",
    "        - It is written in YAML and is contained inside two `---` seperators. \n",
    "        - It includes basic details about the prompt, the model configuration and prompty inputs. \n",
    "\n",
    "    - **Prompt Template:** \n",
    "        - This is the base prompt that is sent to the LLM once the prompty is executed. \n",
    "        - It uses Jinja format to pass values either specified in the front matter or from the application to the LLM.\n",
    "        - Given *'name': Marlene*, the variable *{{name}}* will be replaced by *Marlene* at runtime. \n",
    "\n",
    "**The VS Code extension tool:**\n",
    "- The Prompty extension allows you to run Prompty files directly in VS Code. \n",
    "- It has been pre-installed for this workshop, but you can also find it in the Visual Studio Code Marketplace.\n",
    "\n",
    "\n",
    "### 1.3. Building an AI Agent\n",
    "\n",
    "To help us understand practically how we build an AI agent will build the **Researcher Agent** step by step.\n",
    "<br>In order to build the Researcher agent you will complete the following 3 steps.\n",
    "\n",
    "\n",
    "#### **Step 1:** Build a multi-lingual query generator\n",
    "\n",
    "- The researcher agent generates queries that can be used to look for information online. \n",
    "- It also allows us to find search results in multiple languages. \n",
    "\n",
    "---\n",
    "<img src=\"todo.png\" alt=\"todo icon\" width=\"40\" height=\"40\"> **Tasks for you to do:**\n",
    "\n",
    "> **TODO 1:** Open the [researcher-0.prompty](researcher/researcher-0.prompty) file, read the prompt and **click the play button** on the top right of the file.\n",
    "\n",
    "At the top of the file you should see the following instructions in the sample section:\n",
    "<br>***instructions:** Can you generate queries to find the latest camping trends and what folks are doing in the winter? Use 'en-US' as the market code.*\n",
    " \n",
    " > **TODO 2:** Edit the instructions to use a new language. (For example use *es-ES* instead of *en-US*, to get the results back in Spanish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"coding.png\" alt=\"todo icon\" width=\"45\" height=\"45\"> **Run the code:**\n",
    "\n",
    "You can also execute a Prompty file using the Prompty Python package. \n",
    "\n",
    "> **TODO 3:** Click the play button to the left of the cell to run *researcher-0.prompty* file in Python.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompty\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "\n",
    "instructions = \"Can you generate queries to find the latest camping trends and what folks are doing in the winter? Use 'en-US' as the market code. \"\n",
    "Markdown(prompty.execute(os.getcwd() + \"/researcher/researcher-0.prompty\", inputs={\"instructions\": instructions}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 2:** Give the query generator a list of functions \n",
    "- In order for the researcher to generate even better queries it needs to know which search functions are avaialble to it. \n",
    "- Prompty allows us to pass information to the LLM in the form of a json file using the *${file:filename.json}* format.\n",
    "- In this step we want to give the LLM a list of the functions (sometimes called tools) that it can choose from.\n",
    "- Open the [functions.json](researcher/functions.json) file. Read the descriptions of the **find_information**, **find_entities** and **find_news** functions. \n",
    "- Open the [researcher-1.prompty](researcher/researcher-1.prompty) file and note that *${file:functions.json}* has been added to *tools* under the *parameters* section in the front matter. \n",
    "- Click the run button on the top right of the file and look at the results in the output tab.\n",
    "\n",
    "**Passing a json file to the *tools* parameter in Prompty invokes the LLM to:**\n",
    "- return a list of dictionaries, where each dictionary represents a function to call and its arguments\n",
    "- the *funcion* key contains the generated query and the selected market as arguments\n",
    "- the *name* key contains the name of the most appropriate function to use\n",
    "\n",
    "‚úÖ To complete this step update the instructions passed in the *sample* section of the prompty file to influence which function the LLM chooses. \n",
    "<br>(For example to influence choice of the *find_news* function, use instructions: 'Can you find the latest news about Microsoft?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 3:** Understanding how the LLM chooses which function to call\n",
    "\n",
    "**Let's walk through the code**\n",
    "\n",
    "Let's import `execute_researcher_prompty` from the [researcher3.py](./researcher/researcher3.py) script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/researcher'))\n",
    "\n",
    "from researcher3 import execute_researcher_prompty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Prompty template is configured to load a catalog [functions.json](./researcher/functions.json) with the 3 functions:\n",
    "- `find_information`\n",
    "- `find_entities`\n",
    "- `find_news`\n",
    "\n",
    "Let's test each of one them to get a sense of how the LLM selects them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a.1. Find information\n",
    "\n",
    "Let's see how the LLM can help us find information on the web. It cannot find information per se but it can select amongst a catalog of functions the one which would allow achieving that goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Can you find the best educational material for learning Python programming\"\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "function_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_information` function was selected by the LLM based on the description of the function. It also figured out which parameter values should be passed to the function.\n",
    "\n",
    "Go have a look at the definition of the `find_information` function in [functions.json](./researcher/functions.json) and try to get a sense of why this function was selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a.2. Find entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"Who is the inventor of the Python programming language?\"\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "function_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the `find_entities` function called? Why? Go look at the `find_entities` definition in [functions.json](./researcher/functions.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a.3. Find news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"What's the latest about the Python programming language?\"\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "function_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üêû**BUG ALERT:** A bug has purposefully been left in the [functions.json](./researcher/functions.json) file.\n",
    "\n",
    "Which function call has been selected? If any? With which parameters? Is it the `find_information` function we want?\n",
    "\n",
    "**Exercice**:\n",
    "- Find why the `find_news` function is not the one selected by the LLM\n",
    "- Learn how to steer the LLM to select a given function using its description and parameters\n",
    "- Add the function definition for `find_news` to the [functions.json](./researcher/functions.json) file\n",
    "<details>\n",
    "  <summary>find_news function definition</summary>\n",
    "  \n",
    "```json\n",
    "\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"find_news\",\n",
    "      \"description\": \"Finds jokes on the web given a query. This function uses the Bing Search API to find jokes on the web given a query. The response includes the funniest jokes from the web and should be used if you're looking for a laugh.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"An optimal search query to find jokes on the web using the Bing Search API\"\n",
    "          },\n",
    "          \"market\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The market to search in, e.g. en-US - it should match the language of the query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 4:** Build the functions and execute the research\n",
    "- The researcher has now selected which function to use and has generated a query and market code to pass to it. \n",
    "- We now need to write the Python code for these functions that will pass the queries to the Bing Search API. \n",
    "- We will also use a function in Python to execute the prompty file, instead of running it manually in VS Code. \n",
    "- To put everything together click the play button on the left of the jupyter notebook code cell below below.  \n",
    "- The notebook cell calls the *research* function to run code from **researcher3.py**.\n",
    "- Open the the [researcher3.py](researcher/researcher3.py) file to see this code and try and understand what each function does. \n",
    "\n",
    "‚úÖ To complete this step run the code in the cell below and test it out with different instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from IPython.display import JSON\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/researcher'))\n",
    "\n",
    "from researcher3 import execute_function_calls\n",
    "\n",
    "instructions = \"Can you find the best educational material for learning Python programming\"\n",
    "\n",
    "# Execute the researcher prompty to get a list of functions calls\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "\n",
    "# Execute the function calls\n",
    "research = execute_function_calls(function_calls)\n",
    "research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Congratulations you've build your first AI Agent with Promptyüéâ\n",
    "- [‚úÖ] Step 1: Build a multi-lingual query generator\n",
    "- [‚úÖ] Step 2: Give the query generator a list of functions available\n",
    "- [‚úÖ] Step 3: Build the tools and execute the research\n",
    "\n",
    "We can now succesfully move on to learning outcome 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **Open [next workshop notebook](./workshop-2-tracing.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
